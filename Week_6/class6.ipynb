{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "\n",
    "For many data projects, a [significant proportion of\n",
    "time](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#74d447456f63)\n",
    "is spent collecting and cleaning the data — not performing the analysis.\n",
    "\n",
    "This non-analysis work is often called “data cleaning”.\n",
    "\n",
    "pandas provides very powerful data cleaning tools, which we\n",
    "will demonstrate using the following dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numbers</th>\n",
       "      <th>nums</th>\n",
       "      <th>colors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#23</td>\n",
       "      <td>23</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#24</td>\n",
       "      <td>24</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#18</td>\n",
       "      <td>18</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#14</td>\n",
       "      <td>14</td>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#10</td>\n",
       "      <td>XYZ</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>#35</td>\n",
       "      <td>35</td>\n",
       "      <td>pink</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  numbers nums  colors\n",
       "0     #23   23   green\n",
       "1     #24   24     red\n",
       "2     #18   18  yellow\n",
       "3     #14   14  orange\n",
       "4     #12  NaN  purple\n",
       "5     #10  XYZ    blue\n",
       "6     #35   35    pink"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"numbers\": [\"#23\", \"#24\", \"#18\", \"#14\", \"#12\", \"#10\", \"#35\"],\n",
    "                   \"nums\": [\"23\", \"24\", \"18\", \"14\", np.nan, \"XYZ\", \"35\"],\n",
    "                   \"colors\": [\"green\", \"red\", \"yellow\", \"orange\", \"purple\", \"blue\", \"pink\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would happen if we wanted to try and compute the mean of\n",
    "`numbers`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert #23#24#18#14#12#10#35 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '#23#24#18#14#12#10#35'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1430\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1431\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1432\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c62df3911a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"numbers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11466\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11467\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11468\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  11469\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11470\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4234\u001b[0m                 )\n\u001b[1;32m   4235\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4236\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_reindex_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mdtype_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m                 \u001b[0;31m# e.g. \"foo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not convert {x} to numeric\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert #23#24#18#14#12#10#35 to numeric"
     ]
    }
   ],
   "source": [
    "df[\"numbers\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It throws an error!\n",
    "\n",
    "Can you figure out why? Hint: As always, when looking at error messages, start at the very\n",
    "bottom.\n",
    "\n",
    "The final error says, `TypeError: Could not convert #23#24... to numeric`.\n",
    "\n",
    "---------\n",
    "\n",
    "**Exercise 1**\n",
    "\n",
    "Use the method `replace` to convert the string below into a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2n = \"#39\"\n",
    "c2n = c2n.replace('#', '')\n",
    "c2n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Methods\n",
    "\n",
    "One way to make this change to every element of a column would be to loop through all elements of the column and apply the desired string methods… One significantly faster (and easier) method is to apply a string method to an entire column of data.\n",
    "\n",
    "Most methods that are available to a Python string are also available to a pandas Series that has `dtype` object. We access them by doing `s.str.method_name` where `method_name` is the name of the method. When we apply the method to a Series `s`, it is applied to all rows in the Series in one shot!\n",
    "\n",
    "For example, we can check whether the colors contain blue, as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"colors\"].str.contains(\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**\n",
    "\n",
    "Make a new column called `numbers_str` that contains the elements of\n",
    "`numbers` but without `\"#\"`. Afterwards, show the data types in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numbers_str'] = df['numbers'].str.replace(\"#\", '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Conversions\n",
    "\n",
    "The `dtype` of the `numbers_str` column shows that pandas still treats it as a string even after we have removed the `\"#\"`.\n",
    "\n",
    "We need to convert this column to numbers. The best way to do this is using the `pd.to_numeric` function.\n",
    "\n",
    "This method attempts to convert whatever is stored in a Series into numeric values. For example, after the `\"#\"` removed, the numbers of column `\"numbers\"` are ready to be converted to actual numbers, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numbers_numeric\"] = pd.to_numeric(df[\"numbers_str\"])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert to other types well. Using the `astype` method, we can convert to any of the supported pandas `dtypes`. For example, we can convert our new variable from integers to floats, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numbers_numeric\"] = df[\"numbers_numeric\"].astype(float)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**\n",
    "\n",
    "Convert the column `\"nums\"` to a numeric type and save it to the DataFrame as `\"nums_tonumeric\"`.\n",
    "\n",
    "*Hint:* Notice that there is a missing value, and a value that is not a number. Look at the documentation for `pd.to_numeric` and think about how to overcome this.\n",
    "\n",
    "Why could your solution be a bad idea if used without knowing what your data looks like? \n",
    "\n",
    "*Hint:* Think about what happens when you apply it to the `\"numbers\"` column before replacing the `\"#\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nums_str'] = df['nums'].str.replace(\"XYZ\", '0').replace(np.nan, '0')\n",
    "df\n",
    "df[\"nums_tonumeric\"] = pd.to_numeric(df[\"nums_str\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Answer\n",
    "Could be bad because if we are looking at something like amount of drink a day, then when getting the mean this would mess up our actual mean, etc. Would be best to just remove rows at that point..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**\n",
    "\n",
    "Convert the column `\"numbers_numeric\"` back into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"numbers_numeric\"] = df[\"numbers_numeric\"].astype(int)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**\n",
    "\n",
    "Looking at the other variables, you notice that the missing item should be 12. Replace the missing item with 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nums'] = df['nums'].str.replace(\"XYZ\", '12')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**\n",
    "\n",
    "Often you need to select data based on conditions met by the data itself. \n",
    "\n",
    "Which colors remain if you only include data for which the numbers are above 18?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[df['numbers_numeric']>18]\n",
    "x['colors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study\n",
    "\n",
    "Remember the chipotle data from this week's homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chipotle = pd.read_csv(\"chipotle_raw.csv\")\n",
    "chipotle.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**\n",
    "\n",
    "We'd like you to use this data to answer the following questions.\n",
    "\n",
    "- What is the average price of an item with chicken?  \n",
    "- What is the average price of an item with steak?  \n",
    "- Did chicken or steak produce more revenue (total)? \n",
    "\n",
    "*Hint:* You may need to use on of the string methods shown above, and don't forget to use the variable `quantity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 1\n",
    "chipotle_chicken = chipotle[chipotle[\"item_name\"].str.contains(\"Chicken\")]\n",
    "chipotle_chicken['no$_price'] = chipotle_chicken['item_price'].str.replace(\"$\", '')\n",
    "chipotle_chicken[\"no$_price\"] = chipotle_chicken[\"no$_price\"].astype(float)\n",
    "print(chipotle_chicken['no$_price'].mean())\n",
    "chipotle_chicken.head()\n",
    "#Answer 2\n",
    "chipotle_steak = chipotle[chipotle[\"item_name\"].str.contains(\"Steak\")]\n",
    "chipotle_steak['no$_price_s'] = chipotle_steak['item_price'].str.replace(\"$\", '')\n",
    "chipotle_steak[\"no$_price_s\"] = chipotle_steak[\"no$_price_s\"].astype(float)\n",
    "print(chipotle_steak['no$_price_s'].mean())\n",
    "#Answer 3\n",
    "chipotle_chicken['total_spent'] = chipotle_chicken['quantity'] * chipotle_chicken['no$_price']\n",
    "chipotle_steak['total_spent_s'] = chipotle_steak['quantity'] * chipotle_steak['no$_price_s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipotle_chicken\n",
    "print('The mean of chicken dishes is; ' + str(chipotle_chicken['no$_price'].mean()))\n",
    "print('The mean of steak dishes is; ' + str(chipotle_steak['no$_price_s'].mean()))\n",
    "print('The revenue of chicken dishes is; ' + str(chipotle_chicken['total_spent'].sum()))\n",
    "print('The revenue of steak dishes is; ' + str(chipotle_steak['total_spent_s'].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative -> More clean way of doing it:\n",
    "chipotle['price_numeric'] = pd.to_numeric(chipotle['item_price'].str.replace('$',''))\n",
    "chipotle['revenue'] = chipotle['quantity']*chipotle['price_numeric']\n",
    "chipotle.head()\n",
    "\n",
    "#Answer\n",
    "chicken = chipotle[(chipotle['choice_description'].str.contains('Chicken')==True) | (chipotle['item_name'].str.contains('Chicken')==True)]\n",
    "print(chicken['price_numeric'].mean())\n",
    "steak = chipotle[(chipotle['choice_description'].str.contains('Steak')==True) | (chipotle['item_name'].str.contains('Steak')==True)]\n",
    "print(steak['price_numeric'].mean())\n",
    "print(chicken['revenue'].sum())\n",
    "print(steak['revenue'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s now talk about saving a DataFrame to a file.\n",
    "\n",
    "As a general rule of thumb, if we have a DataFrame `df` and we would like to save to save it as a file of type `FOO`, then we would call the method named `df.to_FOO(...)`.\n",
    "\n",
    "We will show you how this can be done and try to highlight some issues. But, we will not cover all possible options and features — we feel it is best to learn these as you need them by consulting the appropriate documentation.\n",
    "\n",
    "Let’s show `df.to_csv` as an example.\n",
    "\n",
    "Without any additional arguments, the `df.to_csv` function will return a string containing the csv form of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chipotle.head().to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do pass an argument, the first argument will be used as the file name. By default, it ends up in the same folder as your notebook (but you can also specify another path)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipotle.to_csv(\"chipotle.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see above and in the file that the csv-form contains the index, which will appear as a variable once you read the csv-file again in pandas. You can prevent this with `index = False`, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipotle.to_csv(\"chipotle.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**\n",
    "\n",
    "Analogous to above, export the `chipotle` DataFrame as an excel-file `chipotle.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chipotle.to_excel(\"chipotle.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregations and `datetime`\n",
    "\n",
    "Below we will use unemployment data by US state at a monthly frequency, as contained in the file `state_unemployment.csv`. The pandas `read_csv` function will determine most datatypes of the underlying columns. The exception here is that we need to give pandas a hint so it can load up the `Date` column as a Python datetime type, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                datetime64[ns]\n",
      "state                       object\n",
      "LaborForce                 float64\n",
      "UnemploymentRate           float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>state</th>\n",
       "      <th>LaborForce</th>\n",
       "      <th>UnemploymentRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2142945.0</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>319059.0</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2499980.0</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1264619.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>California</td>\n",
       "      <td>16680246.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date       state  LaborForce  UnemploymentRate\n",
       "0 2000-01-01     Alabama   2142945.0               4.7\n",
       "1 2000-01-01      Alaska    319059.0               6.3\n",
       "2 2000-01-01     Arizona   2499980.0               4.1\n",
       "3 2000-01-01    Arkansas   1264619.0               4.4\n",
       "4 2000-01-01  California  16680246.0               5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemp_raw = pd.read_csv(\"state_unemployment.csv\", parse_dates=[\"Date\"])\n",
    "print(unemp_raw.dtypes)\n",
    "unemp_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9**\n",
    "\n",
    "One of the reasons people are concerned about business cycles is that unemployment can increase a lot during recessions. \n",
    "\n",
    "One way to look at unemployment changes is to study the variance of unemployment over time. Which states are relatively volatile? Compute the variance of unemployment for each state.\n",
    "\n",
    "*Hint:* Use `var` and `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LaborForce</th>\n",
       "      <th>UnemploymentRate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>7.775240e+08</td>\n",
       "      <td>4.548286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>2.587950e+08</td>\n",
       "      <td>0.257506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>4.729559e+10</td>\n",
       "      <td>4.179021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>1.568688e+09</td>\n",
       "      <td>1.957209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>5.103886e+11</td>\n",
       "      <td>6.039162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              LaborForce  UnemploymentRate\n",
       "state                                     \n",
       "Alabama     7.775240e+08          4.548286\n",
       "Alaska      2.587950e+08          0.257506\n",
       "Arizona     4.729559e+10          4.179021\n",
       "Arkansas    1.568688e+09          1.957209\n",
       "California  5.103886e+11          6.039162"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_of_states = unemp_raw.groupby('state').var()\n",
    "vars_of_states.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10**\n",
    "\n",
    "Instead of using a built-in aggregation like `var`, it is also possible to write your own aggregation, which you can call with `agg`, as you have seen in Datacamp.\n",
    "\n",
    "Create a function `high_or_low` that takes a pandas Series as argument. The function should print `\"High\"` if the variance of the series is equal to or above 2.5, and should print `\"Low\"` if the variance of the series is below 2.5.\n",
    "\n",
    "Apply your function to find out which states have volatile unemployment, and which don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state\n",
       "Alabama           High\n",
       "Alaska            None\n",
       "Arizona           High\n",
       "Arkansas          None\n",
       "California        High\n",
       "Colorado          High\n",
       "Connecticut       High\n",
       "Delaware          High\n",
       "Florida           High\n",
       "Georgia           High\n",
       "Hawaii            None\n",
       "Idaho             High\n",
       "Illinois          High\n",
       "Indiana           High\n",
       "Iowa              None\n",
       "Kansas            None\n",
       "Kentucky          High\n",
       "Louisiana         None\n",
       "Maine             High\n",
       "Maryland          None\n",
       "Massachusetts     None\n",
       "Michigan          High\n",
       "Minnesota         None\n",
       "Mississippi       High\n",
       "Missouri          High\n",
       "Montana           None\n",
       "Nebraska          None\n",
       "Nevada            High\n",
       "New Hampshire     None\n",
       "New Mexico        None\n",
       "New York          None\n",
       "New jersey        High\n",
       "North Carolina    High\n",
       "North Dakota      None\n",
       "Ohio              High\n",
       "Oklahoma          None\n",
       "Oregon            High\n",
       "Pennsylvania      None\n",
       "Rhode island      High\n",
       "South Carolina    High\n",
       "South Dakota      None\n",
       "Tennessee         High\n",
       "Texas             None\n",
       "Utah              None\n",
       "Vermont           None\n",
       "Virginia          None\n",
       "Washington        High\n",
       "West Virginia     None\n",
       "Wisconsin         High\n",
       "Wyoming           None\n",
       "Name: UnemploymentRate, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def high_or_low(s):\n",
    "    if s.var() < 2.5:\n",
    "        out = 'Low'\n",
    "    else:\n",
    "        out = 'High'\n",
    "        return out\n",
    "        \n",
    "unemp_raw.groupby('state')['UnemploymentRate'].agg(high_or_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 11**\n",
    "\n",
    "Create a DataFrame `unemp_all` containing the unemployment rates, with the US states as columns and `Date` as index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>state</th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alaska</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>Arkansas</th>\n",
       "      <th>California</th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Connecticut</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Florida</th>\n",
       "      <th>Georgia</th>\n",
       "      <th>...</th>\n",
       "      <th>South Dakota</th>\n",
       "      <th>Tennessee</th>\n",
       "      <th>Texas</th>\n",
       "      <th>Utah</th>\n",
       "      <th>Vermont</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-01</th>\n",
       "      <td>4.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-01</th>\n",
       "      <td>3.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-01</th>\n",
       "      <td>3.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>3.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-01</th>\n",
       "      <td>3.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "state       Alabama  Alaska  Arizona  Arkansas  California  Colorado  \\\n",
       "Date                                                                   \n",
       "2017-08-01      4.0     7.2      4.7       3.7         4.6       2.9   \n",
       "2017-09-01      3.9     7.2      4.7       3.7         4.5       3.0   \n",
       "2017-10-01      3.8     7.2      4.7       3.7         4.5       3.0   \n",
       "2017-11-01      3.8     7.2      4.7       3.7         4.5       3.0   \n",
       "2017-12-01      3.8     7.2      4.7       3.7         4.5       3.0   \n",
       "\n",
       "state       Connecticut  Delaware  Florida  Georgia  ...  South Dakota  \\\n",
       "Date                                                 ...                 \n",
       "2017-08-01          4.5       4.6      4.0      4.5  ...           3.4   \n",
       "2017-09-01          4.5       4.5      3.9      4.5  ...           3.4   \n",
       "2017-10-01          4.5       4.5      3.9      4.5  ...           3.4   \n",
       "2017-11-01          4.5       4.5      3.9      4.5  ...           3.4   \n",
       "2017-12-01          4.5       4.5      3.9      4.5  ...           3.4   \n",
       "\n",
       "state       Tennessee  Texas  Utah  Vermont  Virginia  Washington  \\\n",
       "Date                                                                \n",
       "2017-08-01        3.4    4.0   3.2      3.0       3.7         4.8   \n",
       "2017-09-01        3.3    4.0   3.2      2.9       3.6         4.7   \n",
       "2017-10-01        3.3    3.9   3.2      2.9       3.6         4.7   \n",
       "2017-11-01        3.3    3.9   3.2      2.9       3.6         4.7   \n",
       "2017-12-01        3.3    4.0   3.2      2.9       3.6         4.7   \n",
       "\n",
       "state       West Virginia  Wisconsin  Wyoming  \n",
       "Date                                           \n",
       "2017-08-01            5.2        3.3      4.1  \n",
       "2017-09-01            5.3        3.3      4.1  \n",
       "2017-10-01            5.4        3.2      4.2  \n",
       "2017-11-01            5.4        3.2      4.2  \n",
       "2017-12-01            5.4        3.2      4.1  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemp_all = unemp_raw.pivot_table(index='Date', columns='state', values='UnemploymentRate')\n",
    "unemp_all.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 12**\n",
    "\n",
    "One of the advantages of a `DatetimeIndex` is that it is easy to slice.\n",
    "\n",
    "Consider the list of states below. Create a DataFrame `unemp` that contains unemployment rates for only those states between January 2006 and December 2015 (including)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>state</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>California</th>\n",
       "      <th>Florida</th>\n",
       "      <th>Illinois</th>\n",
       "      <th>Michigan</th>\n",
       "      <th>New York</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01</th>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-02-01</th>\n",
       "      <td>4.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-01</th>\n",
       "      <td>4.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-04-01</th>\n",
       "      <td>4.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-01</th>\n",
       "      <td>4.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-01</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01</th>\n",
       "      <td>5.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01</th>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-01</th>\n",
       "      <td>5.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-01</th>\n",
       "      <td>5.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "state       Arizona  California  Florida  Illinois  Michigan  New York  Texas\n",
       "Date                                                                         \n",
       "2006-01-01      4.5         5.0      3.2       5.1       6.8       4.8    5.2\n",
       "2006-02-01      4.4         5.0      3.2       4.9       6.9       4.8    5.1\n",
       "2006-03-01      4.4         4.9      3.1       4.8       6.9       4.7    5.1\n",
       "2006-04-01      4.4         4.9      3.2       4.6       7.0       4.7    5.1\n",
       "2006-05-01      4.3         4.9      3.2       4.6       7.0       4.7    5.1\n",
       "...             ...         ...      ...       ...       ...       ...    ...\n",
       "2015-08-01      6.0         6.0      5.3       5.9       5.2       5.0    4.4\n",
       "2015-09-01      5.9         5.9      5.3       5.9       5.1       5.0    4.4\n",
       "2015-10-01      5.8         5.8      5.2       5.9       5.0       4.9    4.4\n",
       "2015-11-01      5.8         5.7      5.1       6.0       4.9       4.9    4.5\n",
       "2015-12-01      5.7         5.7      5.1       6.1       4.9       4.9    4.5\n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = [\"Arizona\", \"California\", \"Florida\", \"Illinois\",\n",
    "    \"Michigan\", \"New York\", \"Texas\"]\n",
    "unemp = unemp_all.loc[\"2006-01\":\"2015-12\", states]\n",
    "unemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many analytical operations do not necessarily involve an aggregation. The output of a function applied to a Series might need to be a new Series.\n",
    "\n",
    "For example,\n",
    "- Compute the difference in unemployment from month to month (`diff`).\n",
    "- Compute the percentage change in unemployment from month to month (`pct_change`).\n",
    "- Calculate the cumulative sum of elements in each column (`cumsum`)\n",
    "\n",
    "As usual, tab completion is helpful when trying to find such functions.\n",
    "\n",
    "As an example of the use of transforms, the code below shows which state had the largest percentage increase in unemployment. Try to understand how this code arrives at this answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Texas'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemp.pct_change().max().idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 13**\n",
    "\n",
    "The DataFrame `unemp` contains dates starting at the height of the boom before the Great Recession, and ends 10 years later.\n",
    "\n",
    "Which state had the smallest increase (or largest decrease) in unemployment over this period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michigan'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unemp.diff().sum().idxmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
